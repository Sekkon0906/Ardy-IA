
# ==== Model settings ====
MODEL_PROVIDER="ollama"   
# or "openai"

# ==== Ollama ====
OLLAMA_API_URL="http://localhost:11434"
OLLAMA_MODEL="llama2"

# ==== OpenAI ====
# OPENAI_API_KEY="sk-your-openai-key"
# OPENAI_MODEL="gpt-4o-mini"

# ==== OpenAI (via LiteLLM proxy to Ollama) ====
OPENAI_API_BASE="http://localhost:4000"
OPENAI_MODEL="ollama/llama2"
OPENAI_API_KEY="dummy-key"  # not actually used by litellm